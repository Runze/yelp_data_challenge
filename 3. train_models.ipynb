{
 "metadata": {
  "name": "",
  "signature": "sha256:bf5efc252853f539008d3126abc4689a85864fe9e89e3260ed7a068b9913930b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3. Training models using the sentiment scores"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this module, I'm going to train a logistic regression, bagging trees, and gradient boost trees models usng the computed sentiment scores as the sole input variable and the 5-star ratings as the output. The model performance is evaluated and the parameters are tuned using 10-fold cross-validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import cross_validation, metrics, linear_model, ensemble, tree, grid_search, externals\n",
      "from time import time\n",
      "%cd /Users/Runze/Google Drive/Yelp/yelp_dataset_challenge_academic_dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/Runze/Google Drive/Yelp/yelp_dataset_challenge_academic_dataset\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reviews_train = pd.read_pickle('reviews_train.pkl')\n",
      "reviews_train_excl_na = reviews_train.dropna(subset = ['score'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create input and output variables\n",
      "score = reviews_train_excl_na['score']\n",
      "score = np.atleast_2d(score).T # the feature set needs to be 2-dimensional\n",
      "stars = reviews_train_excl_na['stars']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What should we use as the scoring function in choosing the best model or parameters in the cross-validation? Given that this is a multi-label classification problem, the default and the most straightforward metric is the accuracy score, but is that what we care the most, i.e., how many reviews are categorized correctly?\n",
      "\n",
      "In my opinion, given the amount of classes it has and the still fuzzy connections between the review texts and the ultimate star ratings, it may be hard to achieve a high accuracy score. Besides, it may be more important to ensure a definitively positive review is deemed positive and a negative negative than only counting how many are classified correctly or incorrectly. With these in mind, I decided to use a classic regression loss function - mean absolute errors (\"MAE\") to evaulate and select models based on the average deviance between the actual and predicted ratings.\n",
      "\n",
      "However, bear in mind that this is only the *scoring function* used in the cross-valition, not the *loss function* used in the model building process to optimize the fit (e.g., MAE used in regression and gini index used in decision trees). In other words, the models are still created in the usual fashion but are selected using MAE."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scorer_mae = metrics.make_scorer(metrics.mean_absolute_error, greater_is_better = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.1 Logistic regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_clf = linear_model.LogisticRegression(random_state = 2014)\n",
      "\n",
      "t0 = time()\n",
      "logit_scores_mae = cross_validation.cross_val_score(logit_clf, score, stars, cv = 10, scoring = scorer_mae)\n",
      "t1 = time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'logistic regression using mean-absolute-error scoring function'\n",
      "print 'time used: %d seconds' % (t1 - t0)\n",
      "print 'scores: %0.3f (+/-%0.03f)' % (logit_scores_mae.mean(), logit_scores_mae.std())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "logistic regression using mean-absolute-error scoring function\n",
        "time used: 25 seconds\n",
        "scores: -0.768 (+/-0.019)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logistic model finished quickly with decent results, indicating using only the sentiment score, the data are somewhat linearly separable (also as demonstrated in the boxplot in the prior module). The mean scores of the 10-fold cross-validation is 0.768 (the negative sign is added automatically indicating the new scoring function is a loss function), suggesting on average the predicted ratings are within 1-star away from the actual - not too shabby :-)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.2 Bagging trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's try some nonlinear classifiers. Given that we only have one input variable, it doesn't quite make sense to use random forests since its random feature selection is of no use here. Without it, it is effectively reduced to simple bagging trees."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bag_clf = ensemble.BaggingClassifier(tree.DecisionTreeClassifier(), n_estimators = 100, n_jobs = -1, random_state = 2014)\n",
      "\n",
      "t0 = time()\n",
      "bag_scores_mae = cross_validation.cross_val_score(bag_clf, score, stars, cv = 10, scoring = scorer_mae)\n",
      "t1 = time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'bagging trees using mean-absolute-error scoring function'\n",
      "print 'time used: %d seconds' % (t1 - t0)\n",
      "print 'scores: %0.3f (+/-%0.03f)' % (bag_scores_mae.mean(), bag_scores_mae.std())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bagging trees using mean-absolute-error scoring function\n",
        "time used: 2778 seconds\n",
        "scores: -0.857 (+/-0.052)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, it took significantly longer only to produce worse results."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.3 Gradient boost trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try one more ensemble tree-based model. Unlike bagging trees or random forests which focus on reducing variance using bootstrapping, gradient boost trees sequentially try to reduce bias using modified data (e.g., residuals). Based on my experience, it usually produces better results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gradient boost trees\n",
      "param_grid = {'learning_rate': [.01, .1], 'max_depth': [1, 5]}\n",
      "gbm_clf = grid_search.GridSearchCV(ensemble.GradientBoostingClassifier(n_estimators = 100, random_state = 2014),\n",
      "                                   param_grid, cv = 10, scoring = scorer_mae, n_jobs = -1)\n",
      "\n",
      "t0 = time()\n",
      "gbm_clf.fit(score, stars)\n",
      "t1 = time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'gradient boost trees using mean-absolute-error scoring function'\n",
      "print 'time used: %d seconds' % (t1 - t0)\n",
      "print 'best score:', gbm_clf.best_score_, gbm_clf.best_params_\n",
      "print 'grid scores:'\n",
      "for scores in gbm_clf.grid_scores_:\n",
      "    print 'scores: %0.3f (+/-%0.03f)' % (scores[2].mean(), scores[2].std()), scores[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gradient boost trees using mean-absolute-error scoring function\n",
        "time used: 4736 seconds\n",
        "best score: -0.661827807295 {'learning_rate': 0.1, 'max_depth': 1}\n",
        "grid scores:\n",
        "scores: -0.697 (+/-0.064) {'learning_rate': 0.01, 'max_depth': 1}\n",
        "scores: -0.665 (+/-0.057) {'learning_rate': 0.01, 'max_depth': 5}\n",
        "scores: -0.662 (+/-0.062) {'learning_rate': 0.1, 'max_depth': 1}\n",
        "scores: -0.662 (+/-0.062) {'learning_rate': 0.1, 'max_depth': 5}\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nice! It produced the best result in terms of MAE without a big sacrifice on variance. It also took the longest but that's due to parameter tuning.\n",
      "\n",
      "In addition to the three models above, I also tried support vector machines but it took forever to run and I had to kill it in the end. However I doubt its performance will differ or surpass that of the gradient boost trees much as its hinge loss function is similar in shape to logistic regression's if a only linear kernel is used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save the winning model\n",
      "externals.joblib.dump(gbm_clf, 'gbm_clf.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "['gbm_clf.pkl',\n",
        " 'gbm_clf.pkl_01.npy',\n",
        " 'gbm_clf.pkl_02.npy',\n",
        " 'gbm_clf.pkl_03.npy',\n",
        " 'gbm_clf.pkl_04.npy',\n",
        " 'gbm_clf.pkl_05.npy',\n",
        " 'gbm_clf.pkl_06.npy',\n",
        " 'gbm_clf.pkl_07.npy',\n",
        " 'gbm_clf.pkl_08.npy',\n",
        " 'gbm_clf.pkl_09.npy']"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}